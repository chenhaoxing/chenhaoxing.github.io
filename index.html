<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Haoxing Chen, 陈昊星, few-shot learning, metric-learning, self-supervised learning, computer vision, machine learning, Nanjing University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />	
<script src="jquery.min.js"></script>
<title>Haoxing Chen (陈昊星)⭐ </title> 
    
    <head>
        <style type="text/css">
            body{margin: 20px 140px;}
		h2{color:rgb(24,144,255);}
		a{text-decoration:underline}
		a:link {
			color:#e7767f;
			text-decoration:none;
		}
		:visited {
			color:grey;
			text-decoration:none;
		}
		a:hover {
			color:orange;
			text-decoration:none;
		}
		
		a:active {
			color:black;
			text-decoration:none;
		}
		*{ 
 padding: 0px; margin: 0px; } .nav{ 
 list-style: none; /*background-color:rgb(24,144,255);*//*给整个列表设置蓝色背景*/ /*width: 1200px;*/ /*height: 45px;*/ margin: 20px auto; overflow: hidden; zoom: 1; } .nav li{ 
 float: left; width: 13%; } .nav a{ 
 width: 100%; display: inline-block; text-align: center; padding: 5px 0px; text-decoration: none; color: Black; font-weight: bold} .nav a:hover{ 
 background-color:rgb(24,144,255);color: White; } 
        </style>
	<link rel="icon" href="./Files/mambaicon.png">
    </head>
    
	
	
	
<body>
<ul class="nav">
<li><a href="/#-Bio"><font size="3">Biography</font></a></li>
<li><a href="#-News"><font size="3">News</font></a></li>
<li><a href="/#-RI"><font size="3">Research Interest</font></a></li>
<li><a href="#-Pre"><font size="3">Preprints</font></a></li>
<li><a href="/#-Pub"><font size="3">Publications</font></a></li>
<li><a href="#-Awards"><font size="3">Awards</font></a></li>
<li><a href="/#-Service"><font size="3">Services</font></a></li>
</ul>
		
    <div id="layout-content">
        <table class="imgtable">
            <tbody>
                <tr> 
                    
                    <td>
                        <a href="./">
                            <img src="./Files/chx.jpg" width="185px" height="235px">
                        </a>
                        &nbsp;
                   
                    
                    <td align="left">
                        <p>
                            <b>
                                <font size="+3">Haoxing Chen</font>
                                <font size="+3" face="华文行楷">(陈昊星) ⭐</font>
                                </b>
                            <br>
				<br>
                            AI Researcher in Ant Group, Member of Jiangsu Automation/Artificial Intelligence Society
                            <br>
                            <a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzI2ODA2MjAwNw==&scene=123#wechat_redirect">Tiansuan Lab, Machine Intelligence</a>
                            <br>
                            <a href="https://www.antgroup.com/">Ant Group</a>
                            <br>
                            Location⛪: Ant A Space, No. 569 Xixi Road, Hangzhou, China
                            <br>
                            Email: 
                            <a href="mailto:hx.chen@hotmail.com">hx.chen@hotmail.com</a>
                            ; 
                            <a href="mailto:chenhaoxing.chx@antgroup.com">chenhaoxing.chx@antgroup.com</a>
                            <br>
                        </p>

              
                        [
                        <a href="https://scholar.google.com/citations?hl=zh-CN&pli=1&user=BnS7HzAAAAAJ">
                        Google Scholar
                        </a>
                        ]
                        [
                        <a href="https://github.com/chenhaoxing">Github
                        </a>
                        ]
                        </td>
                          <td valign="top" width="58">
                    </td>
                </tr>
            </tbody>
        </table>

        <h2 id="-Bio">Biography</h2>
<ul>
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/ant.png" alt="WSFG" width="200px" height="64px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <em>2022.5-NOW &nbsp;&nbsp;&nbsp;&nbsp;</em> AI Researcher in <a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzI2ODA2MjAwNw==&scene=123#wechat_redirect" target="_blank"> Tiansuan Lab, AntGroup Inc., HangZhou</a>.
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/nju_logo.jpg" alt="WSFG" width="200px" height="64px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <em>2020.9-2023.6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</em>  M.E. in <a href="https://github.com/huaxiongli" target="_blank">Automation and Artificial Intelligence Group, Nanjing University, NJU</a>.
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/seu_logo.jpg" alt="WSFG" width="200px" height="64px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <em>2016.8-2020.6 &nbsp;&nbsp;&nbsp;&nbsp;</em> B.E. in <a href="https://ins.seu.edu.cn/" target="_blank">School of Instrument Science and Engineering</a>, <a href="https://www.seu.edu.cn/" target="_blank">South East University, SEU</a>.
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
 </ul>
<br />

<td align="bottom" colspan="2" style="margin-top:2px">
	
<h2 id="-News">News !</h2>
<div style="height: 250px; overflow: auto;">
<ul>
<li><strong>[July/2023]: </strong>One paper on “Image composition” is accepted to "<a href="https://www.acmmm2023.org/">ACM Multimedia 2023</a>".</li>
<li><strong>[July/2023]: </strong>Our trustworthy AI product "<a href="https://mp.weixin.qq.com/s/j7zA1_G9DyH5I9aqBjUqZw">AntGuard(蚁鉴)</a>" was released at the World Artificial Intelligence Conference(WAIC) and was reported by many media outlets.</li>
<li><strong>[May/2023]: </strong>The code of our new work <a href="https://github.com/chenhaoxing/DiffUTE">DiffUTE</a> <a href="https://arxiv.org/abs/2305.10825">(Paper)</a> is released.</li>
<li><strong>[April/2023]: </strong>One paper on “Contrastive learning” is accepted to <a href="https://icml.cc/Conferences/2023/">ICML 2023</a>.</li>
<li><strong>[Mar./2023]: </strong>We won 3rd place (3/1267) in the classification track and 6th place (6/1156) in the detection track in the <a href="https://tianchi.aliyun.com/competition/entrance/532048/introduction?spm=5176.12281976.0.0.4562331137uPvV">ICDAR Detecting Tampered Text in Images competition</a>.</li>
<li><strong>[Feb./2023]: </strong>One paper on “Vision-language learning” is accepted to <a href="https://cvpr.thecvf.com/">CVPR 2023</a>.</li>
<li><strong>[Feb./2023]: </strong>The code of our new work <a href="https://github.com/chenhaoxing/MACL">MACL</a> <a href="https://arxiv.org/abs/2207.07874">(Paper)</a> is released.</li>
<li><strong>[Jan./2023]: </strong>One paper on “Few-shot learning” is accepted to <a href="http://engine.scichina.com/doi/10.1007/s11432-022-3700-8">SCIS 2023</a>.</li>
<li><strong>[Dec./2022]: </strong>The code of our new work <a href="https://github.com/chenhaoxing/DiffusionInst">DiffusionInst</a> <a href="https://arxiv.org/abs/2212.02773">(Paper)</a> is released.</li>
<li><strong>[Nov./2022]: </strong>The code of our new work <a href="https://github.com/chenhaoxing/HDNet">HDNet</a> <a href="https://arxiv.org/abs/2211.08639">(Paper)</a> is released.</li>
<li><strong>[July/2022]: </strong>One paper on “Affective computing” is accepted to <a href="https://2022.acmmm.org/">ACM MM 2022</a>.</li>
<li><strong>[June/2022]: </strong>One paper on “Few-shot learning” is accepted to <a href="https://www.icpr2022.com/">ICPR 2022</a>.</li>
<li><strong>[June/2022]: </strong>One paper on “Few-shot learning” is accepted to <a href="https://e-nns.org/icann2022/">ICANN 2022</a>.</li>
<li><strong>[May/2022]: </strong>One paper on “Few-shot learning” is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=97">SPL 2022</a>.</li>
</ul>
</div>
</td>
<br />
	    
        <h2 id="-RI">Research Interest </h2>
I work in the field of few-shot learning, image generation, self-supervised learning, computer vision and machine learning. Currently, I focus on the following research topics:
<ul>
<li>Learning with Limited Data: The ability of a model to fit with limited data is essential and necessary due to the instance/label collection cost. How to extract and utilize knowledge from related tasks and domains is the key. Specifically, Haoxing mainly works on how to learn meta-knowledge for few-shot learning.</li>
<li>AIGC: How to design better defense systems to deal with generated attacks has gained extensive attention in recent years. Specifically, Haoxing trys to generate more realistic images and design better detection methods with multi-modal learning.</li>
</ul>
<br />
	    
	    
        <h2 id="-Pre">Preprints</h2>
        
        <ol>
		
		<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/DiffUTE.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Haoxing Chen</b>, Zhuoer Xu, Zhangxuan Gu, Jun Lan, Xing Zheng, Yaohui Li, Changhua Meng, Huijia Zhu, Weiqiang Wang.
                                        <br>
                                        <a href="https://arxiv.org/abs/2305.10825">DiffUTE: Universal Text Editing Diffusion Model.</a>
                                        <br>
                                        <em>arXiv preprint arXiv: 2305.10825</em>
                                        , 2023.
					    <br>
                                        [<a href="./Files/DiffUTE.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/DiffUTE" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>    
	
            <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/arch.jpeg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Zhangxuan Gu, <b>Haoxing Chen</b>
                                        , Zhuoer Xu, Jun Lan, Changhua Meng, Weiqiang Wang.
                                        <br>
                                        <a href="https://arxiv.org/abs/2212.02773">DiffusionInst: Diffusion Model for Instance Segmentation.</a>
                                        <br>
                                        <em>arXiv preprint arXiv: 2212.02773</em>
                                        , 2022.
                                        <br>
                                        [<a href="./Files/Diffusioninst.pdf" target="_blank">Paper</a>]
                                        [<a href="https://github.com/chenhaoxing/DiffusionInst" target="_blank">Code</a>]
				        [<a href="https://github.com/ant-research/diffusion-model-for-instance-segmentation" target="_blank">Code(Ant-Research)</a>]
					[<a href="https://dblp.org/rec/journals/corr/abs-2212-02773.html?view=bibtex" arget="_blank">BibTex</a>]    
					<a href="https://github.com/chenhaoxing/DiffusionInst" target="_blank"><strong><font color=#e74d3c>200+ GitHub Stars</font></strong></a>
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>    
            
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/qpn.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Yaohui Li
                                        , Huaxiong Li, <b>Haoxing Chen</b>, Chunlin Chen.
                                        <br>
                                        <a href="https://arxiv.org/abs/2103.11384">Hierarchical Representation based Query-Specific Prototypical Network for Few-Shot Image Classification.</a>
                                        <br>
                                        <em>arXiv preprint arXiv: 2103.11384</em>
                                        , 2021.
                                        <br>
                                        [<a href="./Files/qpn.pdf" target="_blank">Paper</a>]
					[<a href="https://dblp.org/rec/journals/corr/abs-2103-11384.html?view=bibtex" arget="_blank">BibTex</a>]    
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
    
            
        
        </ol>
<br />
        <h2 id="-Pub">Publications</h2>

	    
        <h3><font color=Black>Conference Articles:</font></h3>
       <ol>

 <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/hd.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Haoxing Chen</b>
                                        , Zhangxuan Gu, Yaohui Li, Jun Lan, Changhua Meng, Weiqiang Wang, Huaxiong Li.
                                        <br>
                                        <a href="https://arxiv.org/abs/2211.08639">Hierarchical Dynamic Image Harmonization.</a>
                                        <br>
                                        In: <em>ACM Multimedia (<b>ACM MM</b>)</em>
                                        , 2023. (<b>CCF-A</b>)
					    <br>
                                        [<a href="./Files/HDNet.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/HDNet" target="_blank">Code</a>]
					[<a href="hhttps://dblp.org/rec/journals/corr/abs-2211-08639.html?view=bibtex" arget="_blank">BibTex</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>    



	       <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/macl.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Zizheng Huang<sup>#</sup>, <b>Haoxing Chen <sup>#</sup>* </b>
                                        , Ziqi Wen, Chao Zhang, Huaxiong Li, Bo Wang, Chunlin Chen. 
                                        <br>
                                        <a href="https://arxiv.org/abs/2207.07874">Model-Aware Contrastive Learning: Towards Escaping the Dilemmas.</a>
                                        <br>
                                        In: <em>International Conference on Machine Learning(<b>ICML</b>)</em>, 2023.(<b>CCF-A</b>)[# Equal contribution, * Corresponding author]
					    <br>
                                        [<a href="./Files/macl.pdf" target="_blank">Paper</a>]
                                        [<a href="https://github.com/chenhaoxing/MACL_ICML2023" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table> 
	       
	       
	       
	       
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
				<img src="./Files/apt2023.jpg" alt="sym" width="220px" height="110px" >
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
					
                                    <p>
                                        Zhangxuan Gu, Zhuoer Xu, <b>Haoxing Chen</b>
                                        , Jun Lan, Changhua Meng, Weiqiang Wang.
                                        <br>
                                        Mobile User Interface Element Detection Via Adaptively Prompt Tuning.
                                        <br>
                                         In: <em>IEEE Conference on Computer Vision and Pattern Recognition(<b>CVPR</b>)</em>, 2023.(<b>CCF-A</b>)
                                        <br>
					[<a href="./Files/CVPR23.pdf" target="_blank">Paper</a>]
					[<a href="https://github.com/antmachineintelligence/MUI-zh" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table> 
	       
	       
	       
        <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
				<img src="./Files/mm_tapp.png" alt="sym" width="220px" height="110px" >
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
					
                                    <p>
                                        Yaohui Li, Yuzhe Yang, Huaxiong Li,<b>Haoxing Chen</b>, Liwu Xu, Leida Li, Yaqian Li, Yandong Guo.
                                        <br>
                                        <a href="https://dl.acm.org/doi/10.1145/3503161.3548244">Transductive Aesthetic Preference Propagation for Personalized Image Aesthetics Assessment.</a>
                                        <br>
                                         In: <em>ACM Multimedia(<b>ACM MM</b>)</em>, 2022.(<b>CCF-A</b>)
                                        <br>
                                        [<a href="./Files/TAPP-PIAA.pdf" target="_blank">Paper</a>]
					[<a href="https://dblp.org/rec/conf/mm/LiYLCXLLG22.html?view=bibtex" arget="_blank">BibTex</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table> 
           
           <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mml.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Haoxing Chen</b>
                                        , Huaxiong Li, Yaohui Li, Chunlin Chen.
                                        <br>
                                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-15919-0_21">Multi-level Metric Learning for Few-shot Image Recognition.</a>
                                        <br>
                                        In: <em>International Conference on Artificial Neural Networks(<b>ICANN</b>)</em>, 2022.(<b>CCF-C</b>)
                                        <br>
                                         [<a href="./Files/chx_mml.pdf" target="_blank">Paper</a>][<a href="https://github.com/chenhaoxing/M2L" target="_blank">Code</a>]
                                    	[<a href="https://dblp.org/rec/conf/icann/ChenLLC22.html?view=bibtex" arget="_blank" >BibTex</a>]
					</p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
           
       <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mata.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Haoxing Chen</b>
                                        , Huaxiong Li, Yaohui Li, Chunlin Chen.
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/document/9955637">Multi-scale Adaptive Task Attention Network for Few-Shot Learning.</a>
                                        <br>
                                        In: <em>International Conference on Pattern Recognition(<b>ICPR</b>)</em>, 2022.(<b>CCF-C</b>)
                                        <br>
                                         [<a href="./Files/chx-mata.pdf" target="_blank">Paper</a>]
                                         [<a href=" https://github.com/chenhaoxing/MATANet" target="_blank">Code</a>]
					 [<a href="https://dblp.org/rec/conf/icpr/ChenLLC22.html?view=bibtex" arget="_blank" >BibTex</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
	     <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mm.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Yaohui Li
                                        , Huaxiong Li, <b>Haoxing Chen</b>, Chunlin Chen.
                                        <br>
                                        <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-88004-0_36">Local Mutual Metric Network for Few-Shot Image Classification.</a>
                                        <br>
                                            In: <em>Chinese Conference on Pattern Recognition and Computer Vision(<b>PRCV</b>)</em>
                                        , 2021. (<b>CCF-C</b>)
                                        <br>
                                          [<a href="./Files/LMMN.pdf" target="_blank">Paper</a>]
					  [<a href="https://dblp.org/rec/conf/prcv/LiLCC21.html?view=bibtex" arget="_blank" >BibTex</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>

	    
	    <h3><font color=Black>Journal Articles:</font></h3>
	<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/ss.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Haoxing Chen</b>
                                        , Huaxiong Li, Yaohui Li, Chunlin Chen.
                                        <br>
                                        <a href="http://engine.scichina.com/doi/10.1007/s11432-022-3700-8">Sparse Spatial Transformers for Few-Shot Learning.</a>
                                        <br>
                                        <em>Sci. China Inf. Sci.</em>
                                        , 2023, In Press. (<b>CCF-A/CAA-A+, SCI/SCIE, Impact Factor: 8.8</b>)
                                        <br>
                                        [<a href="./Files/chx-ssformers.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/ssformers" target="_blank">Code</a>]
					[<a href="https://dblp.org/rec/journals/corr/abs-2109-12932.html?view=bibtex" arget="_blank">BibTex</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
	    
	    
	       <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/asl.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Haoxing Chen</b>
                                        , Huaxiong Li, Yaohui Li, Chunlin Chen.
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/document/9790054">Shaping Visual Representations with Attributes for Few-Shot Recognition. 
					</a>
                                        <br>
                                        <em>IEEE Signal Process. Lett.</em>, vol. 29, pp. 1397-1401, 2022.(<b>CAA-B, SCI/SCIE, Impact Factor: 3.9</b>)
                                        <br>
                                         [<a href="./Files/asl.pdf" target="_blank">Paper</a>]
                                        [<a href="https://github.com/chenhaoxing/ASL" target="_blank">Code</a>]
					[<a href="https://dblp.org/rec/journals/spl/ChenLLC22.html?view=bibtex" arget="_blank" >BibTex</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table> 
	    
	    
	    

	       
        </ol>

     <br />

<h2 id="-Awards">Awards</h2>
<font size="3"> 
<ul>
<li>2023, Nanjing University (NJU) Outstanding Graduates.</li>
<li>2023, 3rd place (3/1267) in the classification track and 6th place (6/1156) in the detection track in the <a href="https://tianchi.aliyun.com/competition/entrance/532048/introduction?spm=5176.12281976.0.0.4562331137uPvV">ICDAR Detecting Tampered Text in Images competition</a>.</li>	
<li>2022, Chinese National Scholarship.</li>
<li>2019, Meritorious Prize in the Mathematical Contest In Modeling (MCM).</li>
<li>2018, First Prize of Jiangsu Province in the National Mathematical Modelling Competition.</li>
<li>2018, National Special Award of the 8th Education Robot Competition Of China (ERCC).</li>
</ul>
</font>
<br />
        
<h2 id="-Service">Haoxing's Services</h2>
<font size="3"> 
<ul>
<li>ACM MM'23, AAAI'23, PAKDD'22, ICPR'22, Reviewer</li>
<li>IEEE Trans on TIP/TCYB/TMM/TNNLS/TCSVT, Reviewer</li>
</ul>
</font>
<br />


<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

</p>
    </tr>
  </tbody>
</table>
</ul>

   
</body>    
</html>

